{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from utils.agent import *\n",
    "from utils.dataset import *\n",
    "\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import sys\n",
    "import traceback\n",
    "import sys\n",
    "import os\n",
    "import tqdm.notebook as tq\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "try:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        from google.colab import drive\n",
    "\n",
    "        drive.mount(\"/content/gdrive\")\n",
    "        LOAD = True\n",
    "        SAVE_MODEL_PATH = \"/content/gdrive/MyDrive/models/\" + \"q_network\"\n",
    "    else:\n",
    "        LOAD = False\n",
    "        SAVE_MODEL_PATH = \"./models/q_network\"\n",
    "except NameError:\n",
    "    LOAD = False\n",
    "    SAVE_MODEL_PATH = \"./models/q_network\"\n",
    "\n",
    "batch_size = 32\n",
    "PATH = \"./datasets/\"\n",
    "arch_type = \"resnet50\"\n",
    "\n",
    "\n",
    "train_loader2012, val_loader2012 = read_voc_dataset(download=LOAD, year=\"2012\")\n",
    "train_loader2007, val_loader2007 = read_voc_dataset(download=LOAD, year=\"2007\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation des différents éléments du jeu de données selon la classe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"cat\",\n",
    "    \"dog\",\n",
    "    \"bird\",\n",
    "    \"motorbike\",\n",
    "    \"diningtable\",\n",
    "    \"train\",\n",
    "    \"tvmonitor\",\n",
    "    \"bus\",\n",
    "    \"horse\",\n",
    "    \"car\",\n",
    "    \"pottedplant\",\n",
    "    \"person\",\n",
    "    \"chair\",\n",
    "    \"boat\",\n",
    "    \"bottle\",\n",
    "    \"bicycle\",\n",
    "    \"aeroplane\",\n",
    "    \"cow\",\n",
    "    \"sheep\",\n",
    "    \"sofa\",\n",
    "]\n",
    "\n",
    "\n",
    "agents_per_class = {}\n",
    "datasets_per_class = sort_class_extract([train_loader2007, train_loader2012])\n",
    "datasets_eval_per_class = sort_class_extract([val_loader2007, val_loader2012])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement sur chaque classe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tq.tqdm(range(len(classes))):\n",
    "    classe = classes[i]\n",
    "    print(\"Classe \" + str(classe) + \"...\")\n",
    "    agents_per_class[classe] = Agent(\n",
    "        classe, alpha=0.2, num_episodes=15, load=False, arch=arch_type\n",
    "    )\n",
    "    agents_per_class[classe].train(datasets_per_class[classe])\n",
    "    del agents_per_class[classe]\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = open(\"logs_over_epochs\", \"r\")\n",
    "d = r.readlines()\n",
    "d = [i.strip() for i in d]\n",
    "\n",
    "print(d[0])\n",
    "print(d[1])\n",
    "print(d[2])\n",
    "print(d[3])\n",
    "print(d[4])\n",
    "print(d[5])\n",
    "print(d[6])\n",
    "print(d[7])\n",
    "print(list(filter(None, d[1].split(\" \"))))\n",
    "\n",
    "\n",
    "aps = {}\n",
    "aps[\"0.1\"] = []\n",
    "aps[\"0.2\"] = []\n",
    "aps[\"0.3\"] = []\n",
    "aps[\"0.4\"] = []\n",
    "aps[\"0.5\"] = []\n",
    "\n",
    "recalls = {}\n",
    "recalls[\"0.1\"] = []\n",
    "recalls[\"0.2\"] = []\n",
    "recalls[\"0.3\"] = []\n",
    "recalls[\"0.4\"] = []\n",
    "recalls[\"0.5\"] = []\n",
    "\n",
    "\n",
    "for i in range(1, 130, 3):  # (17):\n",
    "    a = list(filter(None, d[i + 1].split(\" \")))\n",
    "    b = list(filter(None, d[i + 2].split(\" \")))\n",
    "    c = list(filter(None, d[i + 3].split(\" \")))\n",
    "    print(\"a : \" + str(a))\n",
    "    print(\"b : \" + str(b))\n",
    "    print(\"c : \" + str(c))\n",
    "    aps[\"0.1\"].append(float(a[1]))\n",
    "    aps[\"0.2\"].append(float(a[2]))\n",
    "    aps[\"0.3\"].append(float(a[3]))\n",
    "    aps[\"0.4\"].append(float(a[4]))\n",
    "    aps[\"0.5\"].append(float(a[5]))\n",
    "\n",
    "    recalls[\"0.1\"].append(float(b[1]))\n",
    "    recalls[\"0.2\"].append(float(b[2]))\n",
    "    recalls[\"0.3\"].append(float(b[3]))\n",
    "    recalls[\"0.4\"].append(float(b[4]))\n",
    "    recalls[\"0.5\"].append(float(b[5]))\n",
    "\n",
    "ar = []\n",
    "\n",
    "\n",
    "ar = np.array(ar)\n",
    "print(len(plt.plot(ar)))\n",
    "labels = [\n",
    "    \"Threshold 0.1\",\n",
    "    \"Threshold 0.2\",\n",
    "    \"Threshold 0.3\",\n",
    "    \"Threshold 0.4\",\n",
    "    \"Threshold 0.5\",\n",
    "]\n",
    "colors = [\"r\", \"g\", \"b\", \"brown\", \"purple\"]\n",
    "c = 0\n",
    "for key in aps:\n",
    "    # sns.plot(aps[key], label=labels[c])\n",
    "    sns.scatter(aps[key], label=labels[c], color=colors[c])\n",
    "    c += 1\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"AP\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classes_results.pickle', 'rb') as handle:\n",
    "    resss = pickle.load(handle)\n",
    "\n",
    "# Define the class names\n",
    "classes = [\n",
    "    'cat', 'bird', 'motorbike', 'diningtable', 'train', 'tvmonitor', \n",
    "    'bus', 'horse', 'car', 'pottedplant', 'person', 'chair', 'boat', \n",
    "    'bottle', 'bicycle', 'dog', 'aeroplane', 'cow', 'sheep', 'sofa'\n",
    "]\n",
    "\n",
    "# Define the number of classes (sample count per class)\n",
    "n_classes = {\n",
    "    'cat': 648, 'bird': 553, 'motorbike': 304, 'diningtable': 188, 'train': 369, \n",
    "    'tvmonitor': 290, 'bus': 268, 'horse': 310, 'car': 659, 'pottedplant': 202, \n",
    "    'person': 1301, 'chair': 379, 'boat': 289, 'bottle': 258, 'bicycle': 303, \n",
    "    'dog': 750, 'aeroplane': 432, 'cow': 210, 'sheep': 208, 'sofa': 297\n",
    "}\n",
    "\n",
    "# Define the paper results\n",
    "paper_results = {\n",
    "    'cat': 55.9, 'bird': 38.4, 'motorbike': 55.9, 'diningtable': 46.3, 'train': 54.7, \n",
    "    'tvmonitor': 51.4, 'bus': 56.5, 'horse': 56.9, 'car': 58.8, 'pottedplant': 21.1, \n",
    "    'person': 45.7, 'chair': 21.4, 'boat': 36.5, 'bottle': 21.4, 'bicycle': 61.9, \n",
    "    'dog': 54.2, 'aeroplane': 55.5, 'cow': 40.4, 'sheep': 47.1, 'sofa': 41.5\n",
    "}\n",
    "\n",
    "# Extract AP values from `resss`\n",
    "Y_obtenu = []\n",
    "Y_paper = []\n",
    "res_class = []\n",
    "\n",
    "for cls in classes:\n",
    "    # Get AP from the loaded pickle results safely\n",
    "    ap_value = resss.get(cls, {}).get(0.4, {}).get('ap', 0)  # Default to 0 if key not found\n",
    "    Y_obtenu.append(ap_value)\n",
    "    Y_paper.append(paper_results[cls])\n",
    "    res_class.append(cls)  # Duplicate class for grouping\n",
    "    res_class.append(cls)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Origin': ['Obtenu'] * len(Y_obtenu) + ['Papier'] * len(Y_paper),\n",
    "    'AP': Y_obtenu + Y_paper,\n",
    "    'Classe': res_class\n",
    "})\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(20, 10))  # Adjust size for better readability\n",
    "ax.set_xlabel('AP', fontsize=20)\n",
    "ax.set_ylabel('Classe', fontsize=20)\n",
    "ax.set_xlim([0, 100])\n",
    "\n",
    "sns.barplot(x='AP', y='Classe', data=df, hue='Origin', palette=\"magma\")\n",
    "\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(loc='upper left', fontsize=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save & show plot\n",
    "# plt.savefig('media/comparaison_classes.png', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe = \"dog\"\n",
    "index = random.choice(list(datasets_per_class[classe].keys()))\n",
    "agent = Agent(classe, alpha=0.2, num_episodes=25, load=True, arch=arch_type)\n",
    "\n",
    "for i in range(20):\n",
    "    index = random.choice(list(datasets_per_class[classe].keys()))\n",
    "    image, gt_boxes = extract(index, datasets_per_class[classe])\n",
    "    agent.predict_image(image, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe = random.choice(classes)\n",
    "index = random.choice(list(datasets_per_class[classe].keys()))\n",
    "agent = Agent(classe, alpha=0.2, num_episodes=25, load=True, arch=arch_type)\n",
    "\n",
    "for i in range(20):\n",
    "    index = random.choice(list(datasets_per_class[classe].keys()))\n",
    "    image, gt_boxes = extract(index, datasets_per_class[classe])\n",
    "    agent.predict_image(image, plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
